{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from Exam.PB2.soft_clustering_measure import v_measure\n",
    "\n",
    "\n",
    "BASE_DIR = '/Users/aman/Dropbox/CS6220_Amandeep_Singh/Exam/PB2'\n",
    "DATA_DIR = '{0}/sample_dataset1.txt'.format(BASE_DIR)\n",
    "N_FEATURES = 1000\n",
    "N_TOP_WORDS = 20\n",
    "T = 20\n",
    "K = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/aman/Dropbox/CS6220_Amandeep_Singh/Exam/PB2/whole_dataset.txt', 'r') as file:\n",
    "#     data = file.readlines()\n",
    "#     id = []\n",
    "#     topic = []\n",
    "#     text = []\n",
    "#     for line in data:\n",
    "#         info = line.split(',')\n",
    "#         id.append(info[0])\n",
    "#         topic.append(info[1][1:-1])\n",
    "#         text.append(''.join(info[2:]).replace('\"', ''))\n",
    "#     d = {'id': id, 'topic': topic, 'text': text}\n",
    "#     df = pd.DataFrame(data=d).to_csv(BASE_DIR + '/whole.csv')\n",
    "\n",
    "# with open('/Users/aman/Dropbox/CS6220_Amandeep_Singh/Exam/PB2/whole_dataset.txt', 'r') as file:\n",
    "#     data = file.readlines()\n",
    "#     id = []\n",
    "#     topic = []\n",
    "#     text = []\n",
    "#     for line in data:\n",
    "#         info = line.split(',')\n",
    "#         id.append(info[0])\n",
    "#         topic.append(info[1][2:-1])\n",
    "#         text.append(''.join(info[2:]).replace('\"', ''))\n",
    "#     d = {'id': id, 'topic': topic, 'text': text}\n",
    "#     df = pd.DataFrame(data=d).to_csv(BASE_DIR + '/whole.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = pd.read_csv(BASE_DIR + '/whole.csv', names=['id', 'text', 'topic'], skiprows=1)\n",
    "sample_data = pd.read_csv(BASE_DIR + '/new.csv', names=['id', 'text', 'topic'], skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,max_features=N_FEATURES,stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(whole_data.text.tolist()).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=T, learning_method='online')\n",
    "lda_transform = lda.fit_transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GaussianMixture(n_components=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
       "        means_init=None, n_components=20, n_init=1, precisions_init=None,\n",
       "        random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "        verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.fit(lda_transform[sample_data.id.tolist(),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.126711544023337, -inf, nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aman/.envs/digit_rec/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.py:2508: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=0)\n",
      "/Users/aman/Dropbox/CS6220_Amandeep_Singh/Exam/PB2/soft_clustering_measure.py:50: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (homogeneity + completeness))\n"
     ]
    }
   ],
   "source": [
    "# predictions = gm.predict(lda_transform[sample_data.id.tolist(),:])\n",
    "label_true = [np.argmax(lda.transform(i)[0]) for i in tf[sample_data.id.tolist()]] \n",
    "labels_pred_prob = gm.predict_proba(lda_transform[sample_data.id.tolist(), :])\n",
    "print(v_measure(labels_pred_prob,label_true,20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 14,  7,  6, 12])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argpartition((np.sum(gm.predict_proba(lda_transform[sample_data.id.tolist(), :]),axis=0)),-5)[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: gun 0.0498639980749774 right 0.04517926815549314 rights 0.03704282363250262 games 0.03392671422586689 war 0.03376705520620853 country 0.027161360417462276 military 0.025623780609136393 killed 0.025468446532813365 involved 0.02184275761483738 peace 0.02068653360574068 win 0.02016428045177756 control 0.019340171970219148 red 0.01903214449666049 sex 0.018000629202713427 force 0.017023798346569176 area 0.016770367309243785 league 0.01673649619502486 party 0.016170796258541044 public 0.014879499758387406 action 0.014462554451976379\n",
      "Topic #1: said 0.03931698353158134 did 0.020921712924128706 day 0.019104601609400414 time 0.01831709070799909 went 0.016737312124992396 didn 0.01578168091128047 came 0.015309992993991158 home 0.014066272404117154 years 0.013977943597090526 children 0.013018708896183822 started 0.012955370174476512 took 0.012889582364442695 saw 0.012757253461065704 told 0.012694070883029047 days 0.012505220162372863 just 0.012432963524113723 lord 0.012248382622198668 left 0.012125132958351005 got 0.01082119093149003 father 0.010780960208769485\n",
      "Topic #2: game 0.20441881972004572 russian 0.09480867135411412 ground 0.08696895576570189 turkey 0.08442671283705433 defense 0.07699567722107595 armenia 0.07370689746106007 privacy 0.06508719560563042 package 0.06208982068872776 building 0.04645411007902797 runs 0.0408727028716952 commercial 0.031122015907181885 mode 0.02515179332434447 official 0.024883553300620555 tools 0.014859510393543978 ray 0.010022255151634907 looking 0.009607867298425962 provide 0.009188195011961655 vga 0.005934657752591467 carry 0.005578835397981127 second 0.005412963278419549\n",
      "Topic #3: don 0.04036156775329107 think 0.03084821736740696 just 0.02984193759127926 like 0.025263684396996593 know 0.024751581442293048 people 0.019723601469978626 good 0.017321260963435937 ve 0.016083318533531128 say 0.013964283370522853 way 0.013882192880364078 want 0.01269559827976849 time 0.012636358240322516 really 0.012634391074608436 make 0.011946627964435038 going 0.011652090791334606 ll 0.010556307082998144 does 0.010402485746903917 doesn 0.010098617667308943 sure 0.00978509888520522 things 0.009731353034436799\n",
      "Topic #4: image 0.04707422535562763 source 0.03421389532215739 systems 0.029289021322070313 data 0.02669866113095362 color 0.024952346101759677 version 0.024137555422884684 jpeg 0.021792078217718457 muslims 0.021373900968164945 muslim 0.02083976016197465 format 0.018630743182678627 science 0.018293298496881577 gif 0.01799918075117573 analysis 0.016894298518413783 bits 0.016127088240641862 use 0.01531642515809339 free 0.015290852983240661 sci 0.015111736853865108 sources 0.015040226828454028 tar 0.013349263734578544 support 0.01334339763577207\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 20\n",
    "feature_names = tf_vectorizer.get_feature_names()\n",
    "# def print_top_words(lda_transform, feature_names, n_top_words):\n",
    "for topic_idx, topic in enumerate(lda.components_[[17, 14,  7,  6, 12]]):\n",
    "    message = \"Topic #%d: \" % topic_idx\n",
    "    index = topic.argsort()[:-n_top_words - 1:-1]\n",
    "    message += \" \".join([feature_names[i] + \" \" + str(topic[i] / topic.sum()) for i in index])\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
